{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "import torch\n",
    "import torchvision.models\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
    "import torch.optim as TorchOptimizers\n",
    "import torchvision.transforms.v2 as T\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from torchinfo import summary as torch_summary\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageFile\n",
    "import math\n",
    "import time\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from typing import Callable"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    train_csv_filepath: str\n",
    "    test_csv_filepath: str\n",
    "    submission_filepath: str\n",
    "    images_root_folder: str\n",
    "    image_masks_root_folder: str\n",
    "    training_output_folder: str\n",
    "    saved_weights_filepath: str\n",
    "    device: str\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\" For configuration variables that are shared across environments \"\"\"\n",
    "        self.num_classes = 12\n",
    "        # DeepLabV3 takes a lot of memory. Batch size of 8 with other settings uses just under 16 GB of VRAM\n",
    "        self.batch_size = 8\n",
    "        # With gradient accumulation steps = 4, effective batch size is 8 * 4 = 32.\n",
    "        # This allows for most of the benefits of larger batch sizes\n",
    "        # while fitting within VRAM constraints\n",
    "        self.gradient_accumulation_steps = 4\n",
    "        self.starting_learning_rate = 4e-4\n",
    "        self.max_epochs = 100\n",
    "        self.patience = 20\n",
    "        self.seed = 1234\n",
    "        self.num_workers = 4 if self.device == 'cuda' else 0\n",
    "        self.pin_memory = self.num_workers > 0\n",
    "        self.image_width = 512\n",
    "        self.image_height = 512\n",
    "        self.image_dims = (512, 512)\n",
    "        # For mixed precision training, greatly reduces VRAM usage\n",
    "        self.use_amp = self.device == 'cuda'\n",
    "\n",
    "    # noinspection PyAttributeOutsideInit\n",
    "    def init(self, training):\n",
    "        \"\"\" Adjust configuration setup for training vs inference \"\"\"\n",
    "        self.training = training\n",
    "\n",
    "        if self.training:\n",
    "            os.makedirs(self.training_output_folder, exist_ok=True)\n",
    "\n",
    "        self.imagenet_mean_cpu_tensor = torch.tensor(imagenet_mean_array)\n",
    "        self.imagenet_std_cpu_tensor = torch.tensor(imagenet_std_array)\n",
    "        self.channelwise_imagenet_mean_cpu_tensor = self.imagenet_mean_cpu_tensor.view(3, 1, 1)\n",
    "        self.channelwise_imagenet_std_cpu_tensor = self.imagenet_std_cpu_tensor.view(3, 1, 1)\n",
    "        self.imagenet_mean_gpu_tensor = gpu_tensor(imagenet_mean_array)\n",
    "        self.imagenet_std_gpu_tensor = gpu_tensor(imagenet_std_array)\n",
    "        self.channelwise_imagenet_mean_gpu_tensor = self.imagenet_mean_gpu_tensor.view(3, 1, 1)\n",
    "        self.channelwise_imagenet_std_gpu_tensor = self.imagenet_std_gpu_tensor.view(3, 1, 1)\n",
    "\n",
    "        self.image_transforms = T.Compose([\n",
    "            T.ToImage(),\n",
    "            T.Resize(self.image_dims, interpolation=T.InterpolationMode.BILINEAR),\n",
    "            T.ToDtype(torch.float32, scale=True),\n",
    "            T.Normalize(self.imagenet_mean_cpu_tensor, self.imagenet_std_cpu_tensor),\n",
    "        ])\n",
    "\n",
    "config: Config = None\n",
    "\"\"\" Set to environment-relevant config before training/inference \"\"\";"
   ],
   "id": "98d5f56f48340861",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "local_config = Config(\n",
    "    train_csv_filepath='data/train.csv',\n",
    "    test_csv_filepath='data/test.csv',\n",
    "    submission_filepath='data/submission.csv',\n",
    "    images_root_folder='data/images/',\n",
    "    image_masks_root_folder='data/masks/',\n",
    "    training_output_folder='data_gen/training_output/',\n",
    "    saved_weights_filepath='data_gen/training_output/model_weights.pth',\n",
    "    device='cpu',\n",
    ")\n",
    "kaggle_config = Config(\n",
    "    train_csv_filepath='/kaggle/input/opencv-pytorch-segmentation-project-round2/train.csv',\n",
    "    test_csv_filepath='/kaggle/input/opencv-pytorch-segmentation-project-round2/test.csv',\n",
    "    images_root_folder='/kaggle/input/opencv-pytorch-segmentation-project-round2/imgs/imgs/',\n",
    "    image_masks_root_folder='/kaggle/input/opencv-pytorch-segmentation-project-round2/masks/masks/',\n",
    "    submission_filepath='/kaggle/working/submission.csv',\n",
    "    training_output_folder='/kaggle/working/training_output/',\n",
    "    saved_weights_filepath='/kaggle/working/training_output/model_weights.pth',\n",
    "    device='cuda',\n",
    ")"
   ],
   "id": "379118cc8908681e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "imagenet_mean_array = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "imagenet_std_array = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "# 12 visually diverse colors for semantic segmentation classes\n",
    "CLASS_COLORS = np.array([\n",
    "    [0, 0, 0],        # 0: Black\n",
    "    [255, 0, 0],      # 1: Red\n",
    "    [0, 255, 0],      # 2: Green\n",
    "    [0, 0, 255],      # 3: Blue\n",
    "    [255, 255, 0],    # 4: Yellow\n",
    "    [255, 0, 255],    # 5: Magenta\n",
    "    [0, 255, 255],    # 6: Cyan\n",
    "    [255, 128, 0],    # 7: Orange\n",
    "    [128, 0, 255],    # 8: Purple\n",
    "    [0, 128, 255],    # 9: Light Blue\n",
    "    [255, 128, 128],  # 10: Pink\n",
    "    [128, 255, 128],  # 11: Light Green\n",
    "], dtype=np.uint8)\n",
    "\n",
    "def gpu_tensor(numpy_array):\n",
    "    return torch.tensor(numpy_array, device=config.device)\n",
    "\n",
    "def visualize_image(image_tensor):\n",
    "    \"\"\" Input tensor should be on gpu \"\"\"\n",
    "    image = denormalize(image_tensor, config.channelwise_imagenet_mean_gpu_tensor, config.channelwise_imagenet_std_gpu_tensor)\n",
    "    image = torch.clamp(image, 0, 1)\n",
    "    image = image.permute(1, 2, 0).cpu().numpy()\n",
    "    image = (image * 255).astype('uint8')\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def visualize_mask(mask_tensor):\n",
    "    \"\"\" mask_tensor: gpu image tensor with pixel intensity indicating class (0-11) \"\"\"\n",
    "    mask = mask_tensor.cpu().numpy()\n",
    "    mask = np.clip(mask, 0, config.num_classes - 1).astype(np.int32)\n",
    "    colored_mask = CLASS_COLORS[mask]\n",
    "    plt.imshow(colored_mask)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def normalize(tensor, mean, std):\n",
    "    return (tensor - mean) / std\n",
    "\n",
    "def denormalize(tensor, mean, std):\n",
    "    return tensor * std + mean"
   ],
   "id": "5fe591d8201d9401",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class ImageSegmentationDataset(TorchDataset):\n",
    "    image_ids: np.ndarray\n",
    "    image_transforms: Callable\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        image = Image.open(f'{config.images_root_folder}{image_id}.jpg')\n",
    "        mask = Image.open(f'{config.image_masks_root_folder}{image_id}.png')\n",
    "\n",
    "        # Resize mask using nearest-neighbor to preserve class indices\n",
    "        if config.image_dims is not None:\n",
    "            mask = mask.resize(config.image_dims, resample=Image.NEAREST)\n",
    "\n",
    "        transformed_image = self.image_transforms(image)\n",
    "        # Convert mask to tensor directly - no normalization\n",
    "        # Mask contains class indices 0-11, shape becomes (H, W)\n",
    "        mask_array = np.array(mask)\n",
    "        transformed_mask = torch.from_numpy(mask_array).long()\n",
    "\n",
    "        return transformed_image, transformed_mask"
   ],
   "id": "8b17b13f2b9863a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test_model = deeplabv3_resnet50(weights=DeepLabV3_ResNet50_Weights.DEFAULT)\n",
    "# torch_summary(test_model)"
   ],
   "id": "a179e4dbb6b7be38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test_model"
   ],
   "id": "6412d6b6bcba0ef0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# aux_classifier_children = test_model.aux_classifier.children()\n",
    "# for layer in aux_classifier_children:\n",
    "#     print(layer)"
   ],
   "id": "4f260a1372acb3c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_deeplab_v3_model() -> nn.Module:\n",
    "    # Prevent downloads during inference (relevant for kaggle competitions)\n",
    "    weights_backbone = ResNet50_Weights.DEFAULT if config.training else None\n",
    "    # Otherwise, initialize resnet50 backbone with imagenet weights\n",
    "    model = deeplabv3_resnet50(\n",
    "        weights=None,\n",
    "        weights_backbone=weights_backbone,\n",
    "        num_classes=config.num_classes,\n",
    "        aux_loss=True,\n",
    "    )\n",
    "\n",
    "    # Freeze resnet50 backbone\n",
    "    for param in model.backbone.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Enable fine-tuning of classifier and aux-classifier\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in model.aux_classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    model.to(config.device)\n",
    "\n",
    "    return model"
   ],
   "id": "c860298ad225777f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def dice_coefficient_batch(pred_logits, true_masks, num_classes):\n",
    "    \"\"\"Compute per-class intersection and union for a batch.\n",
    "    \n",
    "    Args:\n",
    "        pred_logits: (B, C, H, W) raw model output logits\n",
    "        true_masks: (B, H, W) ground truth class indices\n",
    "        num_classes: number of classes\n",
    "    \n",
    "    Returns:\n",
    "        intersection: (num_classes,) tensor\n",
    "        union: (num_classes,) tensor\n",
    "    \"\"\"\n",
    "    pred_classes = pred_logits.argmax(dim=1)  # (B, H, W)\n",
    "    \n",
    "    intersection = torch.zeros(num_classes, device=pred_logits.device)\n",
    "    union = torch.zeros(num_classes, device=pred_logits.device)\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        pred_c = (pred_classes == c)\n",
    "        true_c = (true_masks == c)\n",
    "        intersection[c] = (pred_c & true_c).sum()\n",
    "        union[c] = pred_c.sum() + true_c.sum()\n",
    "    \n",
    "    return intersection, union\n",
    "\n",
    "def compute_mean_dice(total_intersection, total_union):\n",
    "    \"\"\"Compute mean Dice score from accumulated intersection/union values.\"\"\"\n",
    "    valid = total_union > 0\n",
    "    dice = torch.zeros_like(total_intersection)\n",
    "    dice[valid] = (2 * total_intersection[valid]) / total_union[valid]\n",
    "    return dice[valid].mean().item()\n",
    "\n",
    "def train_one_epoch(start_time, model, loader, optimizer, loss_function, scaler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # Running sums for incremental Dice computation\n",
    "    total_intersection = torch.zeros(config.num_classes, device=config.device)\n",
    "    total_union = torch.zeros(config.num_classes, device=config.device)\n",
    "\n",
    "    num_batches = math.ceil(len(loader.dataset) / config.batch_size)\n",
    "    accumulation_steps = config.gradient_accumulation_steps\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch_number, (x, y) in enumerate(loader):\n",
    "        print(f't={time.time() - start_time:.2f}: Loading training batch {batch_number + 1}/{num_batches}')\n",
    "\n",
    "        x = x.to(config.device, non_blocking=True)\n",
    "        y = y.to(config.device, non_blocking=True)\n",
    "\n",
    "        if batch_number == 0:\n",
    "            allocated = torch.cuda.memory_allocated(config.device) / 1024**3\n",
    "            reserved = torch.cuda.memory_reserved(config.device) / 1024**3\n",
    "            print(f'Memory allocated={allocated:.2f} GiB, reserved={reserved:.2f} GiB')\n",
    "            print(f'First image:')\n",
    "            visualize_image(x[0])\n",
    "            print(f'First mask (unique values: {torch.unique(y[0]).tolist()}):')\n",
    "            visualize_mask(y[0])\n",
    "\n",
    "        # Mixed precision forward pass\n",
    "        with torch.amp.autocast('cuda', enabled=config.use_amp):\n",
    "            output = model(x)\n",
    "            preds = output['out'] if isinstance(output, dict) else output\n",
    "            loss = loss_function(preds, y)\n",
    "            # Scale loss for gradient accumulation\n",
    "            loss = loss / accumulation_steps\n",
    "\n",
    "        # Mixed precision backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Update weights every accumulation_steps batches\n",
    "        if (batch_number + 1) % accumulation_steps == 0 or (batch_number + 1) == num_batches:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item() * accumulation_steps * x.size(0)\n",
    "\n",
    "        # Compute batch Dice incrementally (no accumulation)\n",
    "        with torch.no_grad():\n",
    "            batch_inter, batch_union = dice_coefficient_batch(preds, y, config.num_classes)\n",
    "            total_intersection += batch_inter\n",
    "            total_union += batch_union\n",
    "        \n",
    "        # Clean up to free memory\n",
    "        del output, preds, loss, x, y\n",
    "        \n",
    "    # Clear GPU cache at end of epoch\n",
    "    if config.device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_score = compute_mean_dice(total_intersection, total_union)\n",
    "\n",
    "    return epoch_loss, epoch_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch(start_time, model, loader, loss_function):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Running sums for incremental Dice computation\n",
    "    total_intersection = torch.zeros(config.num_classes, device=config.device)\n",
    "    total_union = torch.zeros(config.num_classes, device=config.device)\n",
    "    \n",
    "    num_batches = math.ceil(len(loader.dataset) / config.batch_size)\n",
    "    for batch_number, (x, y) in enumerate(loader):\n",
    "        print(f't={time.time() - start_time:.2f}: Loading validation batch {batch_number + 1}/{num_batches}')\n",
    "\n",
    "        x = x.to(config.device, non_blocking=True)\n",
    "        y = y.to(config.device, non_blocking=True)\n",
    "\n",
    "        if batch_number == 0:\n",
    "            print('First image:')\n",
    "            visualize_image(x[0])\n",
    "            print(f'First mask (unique values: {torch.unique(y[0]).tolist()}):')\n",
    "            visualize_mask(y[0])\n",
    "\n",
    "        # Mixed precision inference\n",
    "        with torch.amp.autocast('cuda', enabled=config.use_amp):\n",
    "            output = model(x)\n",
    "            preds = output['out'] if isinstance(output, dict) else output\n",
    "            loss = loss_function(preds, y)\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)\n",
    "\n",
    "        # Compute batch Dice incrementally (no accumulation)\n",
    "        batch_inter, batch_union = dice_coefficient_batch(preds, y, config.num_classes)\n",
    "        total_intersection += batch_inter\n",
    "        total_union += batch_union\n",
    "        \n",
    "        # Clean up to free memory\n",
    "        del output, preds, loss, x, y\n",
    "    \n",
    "    # Clear GPU cache at end of epoch\n",
    "    if config.device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    epoch_loss = running_loss / len(loader.dataset)\n",
    "    epoch_score = compute_mean_dice(total_intersection, total_union)\n",
    "\n",
    "    return epoch_loss, epoch_score"
   ],
   "id": "792dd9fa410a1464",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train():\n",
    "    config.init(training=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print('t=0: Starting data prep and model loading')\n",
    "\n",
    "    effective_batch_size = config.batch_size * config.gradient_accumulation_steps\n",
    "    run = wandb.init(\n",
    "        project='drone_image_segmentation',\n",
    "        name=f'run={int(start_time)}',\n",
    "        config={\n",
    "            'batch_size': config.batch_size,\n",
    "            'gradient_accumulation_steps': config.gradient_accumulation_steps,\n",
    "            'effective_batch_size': effective_batch_size,\n",
    "            'learning_rate': config.starting_learning_rate,\n",
    "            'max_epochs': config.max_epochs,\n",
    "            'seed': config.seed,\n",
    "            'model': 'deeplabv3_resnet50',\n",
    "            'optimizer': 'Adam',\n",
    "            'image_size': config.image_dims,\n",
    "            'use_amp': config.use_amp,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    train_df = pd.read_csv(config.train_csv_filepath)\n",
    "    train_array = train_df['ImageID'].to_numpy()\n",
    "    train_ids, val_ids = train_test_split(train_array, test_size=0.2, random_state=config.seed)\n",
    "\n",
    "    model = create_deeplab_v3_model()\n",
    "\n",
    "    wandb.watch(model, log='gradients', log_freq=100)\n",
    "\n",
    "    train_dataset = ImageSegmentationDataset(train_ids, config.image_transforms)\n",
    "    val_dataset = ImageSegmentationDataset(val_ids, config.image_transforms)\n",
    "\n",
    "    def loader(ds, shuffle):\n",
    "        return DataLoader(ds, shuffle=shuffle, batch_size=config.batch_size, num_workers=config.num_workers, pin_memory=config.pin_memory)\n",
    "\n",
    "    train_loader = loader(train_dataset, shuffle=True)\n",
    "    val_loader = loader(val_dataset, shuffle=False)\n",
    "\n",
    "    # Use CrossEntropyLoss for multi-class segmentation with class indices\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = TorchOptimizers.Adam(model.parameters(), lr=config.starting_learning_rate)\n",
    "    \n",
    "    # Mixed precision scaler\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=config.use_amp)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_loss_epoch = -1\n",
    "    best_val_score = float('-inf')\n",
    "    best_val_score_epoch = -1\n",
    "\n",
    "    history = dict(train_loss=[], val_loss=[], train_score=[], val_score=[], best_val_score_epoch=dict(), best_val_loss_epoch=dict())\n",
    "\n",
    "    training_start_time = time.time()\n",
    "    print(f't={training_start_time - start_time:.2f}: Starting training')\n",
    "    print(f'Batch size: {config.batch_size}, Gradient accumulation: {config.gradient_accumulation_steps}, Effective batch size: {effective_batch_size}')\n",
    "    print(f'Image size: {config.image_dims}, AMP enabled: {config.use_amp}')\n",
    "    torch.manual_seed(config.seed)\n",
    "\n",
    "    best_score_weights_path = config.training_output_folder + 'best_model_weights.pth'\n",
    "    best_loss_weights_path = config.training_output_folder + 'best_loss_model_weights.pth'\n",
    "    \n",
    "    epochs_since_best = 0\n",
    "\n",
    "    for epoch in range(1, config.max_epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        print(f't={epoch_start_time - start_time:.2f}: Starting epoch {epoch}')\n",
    "        train_loss, train_score = train_one_epoch(start_time, model, train_loader, optimizer, loss_function, scaler)\n",
    "        val_loss, val_score = validate_one_epoch(start_time, model, val_loader, loss_function)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_score'].append(train_score)\n",
    "        history['val_score'].append(val_score)\n",
    "\n",
    "        print(f'================ Epoch {epoch:03d} stats ==================')\n",
    "        print(f'train_loss: {train_loss:.4f}  val_loss: {val_loss:.4f}')\n",
    "        print(f'train_score: {train_score:.4f}  val_score: {val_score:.4f}')\n",
    "        print('===================================================')\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'train_score': train_score,\n",
    "                'val_score': val_score,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_val_loss_epoch = epoch\n",
    "            torch.save(model.state_dict(), best_loss_weights_path)\n",
    "\n",
    "        if val_score > best_val_score:\n",
    "            best_val_score = val_score\n",
    "            best_val_score_epoch = epoch\n",
    "            epochs_since_best = 0\n",
    "            torch.save(model.state_dict(), best_score_weights_path)\n",
    "        else:\n",
    "            epochs_since_best += 1\n",
    "            if epochs_since_best >= config.patience:\n",
    "                break\n",
    "\n",
    "    history['best_val_score_epoch']['epoch'] = best_val_score_epoch\n",
    "    history['best_val_score_epoch']['val_score'] = best_val_score\n",
    "    history['best_val_loss_epoch']['epoch'] = best_val_loss_epoch\n",
    "    history['best_val_loss_epoch']['val_loss'] = best_val_loss\n",
    "\n",
    "    print()\n",
    "    print('==================== Results ======================')\n",
    "    print(f'Best val score epoch: {best_val_score_epoch}')\n",
    "    print(f'Best val score: {best_val_score:.4f}')\n",
    "    print(f'Best val loss epoch: {best_val_loss_epoch}')\n",
    "    print(f'Best val loss: {best_val_loss:.2f}')\n",
    "    print('===================================================')\n",
    "    print()\n",
    "\n",
    "    wandb.run.summary['best_val_score'] = best_val_score\n",
    "    wandb.run.summary['best_val_score_epoch'] = best_val_score_epoch\n",
    "    wandb.run.summary['best_val_loss'] = best_val_loss\n",
    "    wandb.run.summary['best_val_loss_epoch'] = best_val_loss_epoch\n",
    "\n",
    "    train_score = history['train_score']\n",
    "    val_score = history['val_score']\n",
    "    epochs = list(range(1, len(train_score) + 1))\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    plt.plot(epochs, train_score, label='train_score', marker='o')\n",
    "    plt.plot(epochs, val_score, label='val_score', marker='o')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Train vs Validation Score per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    wandb.log({\"score_curve\": wandb.Image(plt.gcf())})\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    with open(config.training_output_folder + 'history.json', 'w') as json_file:\n",
    "        json.dump(history, json_file, indent=4)\n",
    "\n",
    "    wandb.save(best_score_weights_path)\n",
    "    wandb.save(best_loss_weights_path)\n",
    "    wandb.save(config.training_output_folder + 'history.json')\n",
    "\n",
    "    wandb.finish()"
   ],
   "id": "b2fd33683b458063",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# wandb_key = user_secrets.get_secret(\"wandb_key\")\n",
    "# !wandb login $wandb_key"
   ],
   "id": "451f50178e5f61bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = kaggle_config\n",
    "train()"
   ],
   "id": "1e50a87e647e8e42",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
